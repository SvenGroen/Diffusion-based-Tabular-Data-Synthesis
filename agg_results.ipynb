{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating results to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc-diff</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1-diff</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>roc_auc-diff</th>\n",
       "      <th>sim_score</th>\n",
       "      <th>sim_score-diff</th>\n",
       "      <th>basic_score</th>\n",
       "      <th>basic_score-diff</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>ml_score-diff</th>\n",
       "      <th>sup_score</th>\n",
       "      <th>sup_score-diff</th>\n",
       "      <th>pmse_score</th>\n",
       "      <th>pmse_score-diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tab-ddpm</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>-0.0144</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>-0.1098</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>-0.8471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tab-ddpm-bgm</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>-0.0110</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>-0.0111</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>-0.2180</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>-0.0280</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>-0.1532</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.8816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         method     acc  acc-diff      f1  f1-diff  roc_auc  roc_auc-diff  \\\n",
       "0          real  0.8742    0.0000  0.8152   0.0000   0.9276        0.0000   \n",
       "0      tab-ddpm  0.8598   -0.0144  0.7941  -0.0211   0.9128       -0.0148   \n",
       "0  tab-ddpm-bgm  0.8632   -0.0110  0.7985  -0.0167   0.9165       -0.0111   \n",
       "\n",
       "   sim_score  sim_score-diff  basic_score  basic_score-diff  ml_score  \\\n",
       "0     0.9598          0.0000       0.9922            0.0000    0.9975   \n",
       "0     0.7586         -0.2012       0.9730           -0.0192    0.9923   \n",
       "0     0.7418         -0.2180       0.9642           -0.0280    0.9955   \n",
       "\n",
       "   ml_score-diff  sup_score  sup_score-diff  pmse_score  pmse_score-diff  \n",
       "0         0.0000     0.9839          0.0000      0.8820           0.0000  \n",
       "0        -0.0052     0.8741         -0.1098      0.0349          -0.8471  \n",
       "0        -0.0020     0.8307         -0.1532      0.0004          -0.8816  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = json.load(open(\"secrets.json\", \"r\"))[\"Experiment_Folder\"]\n",
    "\n",
    "method2exp = {\n",
    "    \"real\": \"adult/20_12_2022-REAL-BASELINE/outputs/exp/adult/ddpm_real/final_eval/\",\n",
    "    \"tab-ddpm\": \"adult/21_12_2022-identity-50optuna-ts26048-catboost-tune-CatboostAndSimilarityEval-syntheticEval/outputs/exp/adult/ddpm_identity_best/final_eval/\",\n",
    "    \"tab-ddpm-bgm\": \"adult/20_12_2022-bgm-50optuna-ts26048-catboost-tune-CatboostAndSimilarityEval-syntheticEval/outputs/exp/adult/ddpm_bgm_best/final_eval/\",\n",
    "    # \"smote\": \"exp/{}/smote/\",\n",
    "    # \"ctabgan+\": \"exp/{}/ctabgan-plus/\",\n",
    "    # \"ctabgan\": \"exp/{}/ctabgan/\",\n",
    "    # \"tvae\": \"exp/{}/tvae/\"\n",
    "} \n",
    "for k,v in method2exp.items():\n",
    "    method2exp[k] = Path(os.path.join(base_path, v))\n",
    "\n",
    "eval_file = \"eval_catboost.json\"\n",
    "sim_file = \"results_similarity.json\"\n",
    "show_std = False\n",
    "columns = [\"method\"] \n",
    "# df = pd.DataFrame(columns=[\"method\"] + [_[:3].upper() for _ in DATASETS])\n",
    "df = []\n",
    "for algo in method2exp: \n",
    "    base_df = pd.DataFrame([algo], columns=[\"method\"])\n",
    "    metric_df = pd.DataFrame()\n",
    "    metrics=[\"acc\",\"f1\",\"roc_auc\"]\n",
    "\n",
    "    if not os.path.exists(method2exp[algo] / eval_file):\n",
    "        print(f\"File {eval_file} not found for {algo}\")\n",
    "        metric_df = pd.DataFrame([[\"---\"]*len(metrics)], columns=metrics)\n",
    "\n",
    "    else:\n",
    "        res_dict = lib.load_json(method2exp[algo] / eval_file)\n",
    "        for metric in metrics:\n",
    "            if algo == \"real\":\n",
    "                res = f'{res_dict[\"real\"][\"test\"][metric + \"-mean\"]:.4f}' \n",
    "                if show_std: res += f'+-{res_dict[\"real\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "                metric_df[metric] = [res]\n",
    "            else:\n",
    "                res = f'{res_dict[\"synthetic\"][\"test\"][metric + \"-mean\"]:.4f}'\n",
    "                if show_std: res += f'+-{res_dict[\"synthetic\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "                metric_df[metric] = [res]\n",
    "\n",
    "    sim_metrics = [\"score\", \"basic_score\", \"ml_score\",\"sup_score\", \"pmse_score\"]\n",
    "    if not os.path.exists(method2exp[algo] / sim_file):\n",
    "        print(f\"File {sim_file} not found for {algo}\")\n",
    "        sim_df = pd.DataFrame([[\"---\"]*len(sim_metrics)], columns=sim_metrics)\n",
    "    else:\n",
    "        sim_res_dict = lib.load_json(method2exp[algo] / sim_file)\n",
    "        sim_df = pd.DataFrame([sim_res_dict[\"sim_score\"]], columns=sim_metrics)\n",
    "    # rename score to sim_score\n",
    "    sim_df = sim_df.rename(columns={\"score\": \"sim_score\"})    \n",
    "    # format all floats to :.4f\n",
    "    sim_df = sim_df.applymap(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "\n",
    "    base_df = pd.concat([base_df, metric_df, sim_df], axis=1)\n",
    "    \n",
    "    df.append(base_df)\n",
    "\n",
    "\n",
    "calculate_diff = True\n",
    "results = pd.concat(df, axis=0)\n",
    "metrics = results.columns.tolist()\n",
    "metrics.remove(\"method\")\n",
    "cols= [\"method\"]\n",
    "if calculate_diff:\n",
    "    for metric in metrics:\n",
    "        results[metric] = pd.to_numeric(results[metric])\n",
    "        results[f\"{metric}-diff\"] = results[metric] - results.loc[results[\"method\"] == \"real\", metric].values[0]\n",
    "        cols.append(metric)\n",
    "        cols.append(f\"{metric}-diff\")\n",
    "    results=results.reindex(cols, axis=1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS = [\n",
    "#     \"abalone\",\n",
    "#     \"adult\",\n",
    "#     \"buddy\",\n",
    "#     \"california\",\n",
    "#     \"cardio\",\n",
    "#     \"churn2\",\n",
    "#     \"default\",\n",
    "#     \"diabetes\",\n",
    "#     \"fb-comments\",\n",
    "#     \"gesture\",\n",
    "#     \"higgs-small\",\n",
    "#     \"house\",\n",
    "#     \"insurance\",\n",
    "#     \"king\",\n",
    "#     \"miniboone\",\n",
    "#     \"wilt\"\n",
    "# ]\n",
    "\n",
    "# _REGRESSION = [\n",
    "#     \"abalone\",\n",
    "#     \"california\",\n",
    "#     \"fb-comments\",\n",
    "#     \"house\",\n",
    "#     \"insurance\",\n",
    "#     \"king\",\n",
    "# ]\n",
    "\n",
    "# method2exp = {\n",
    "#     \"real\": \"adult/20_12_2022-REAL-BASELINE/outputs/adult/ddpm_real/final_eval/\",\n",
    "#     \"tab-ddpm-bgm\": \"adult/20_12_2022-bgm-50optuna-ts26048-catboost-tune-CatboostAndSimilarityEval-syntheticEval/outputs/exp/adult/ddpm_bgm_best/final_eval/\",\n",
    "#     # \"tab-ddpm\": \"exp/{}/ddpm_cb_best/\",\n",
    "#     # \"smote\": \"exp/{}/smote/\",\n",
    "#     # \"ctabgan+\": \"exp/{}/ctabgan-plus/\",\n",
    "#     # \"ctabgan\": \"exp/{}/ctabgan/\",\n",
    "#     # \"tvae\": \"exp/{}/tvae/\"\n",
    "# }\n",
    "\n",
    "# eval_file = \"eval_catboost.json\"\n",
    "# sim_file = \"results_similarity.json\"\n",
    "# show_std = False\n",
    "# df = pd.DataFrame(columns=[\"method\"] + [_[:3].upper() for _ in DATASETS])\n",
    "\n",
    "# for algo in method2exp: \n",
    "#     algo_res = []\n",
    "#     for ds in DATASETS:\n",
    "#         if not os.path.exists(os.path.join(method2exp[algo].format(ds), eval_file)):\n",
    "#             algo_res.append(\"--\")\n",
    "#             continue\n",
    "#         metric = \"r2\" if ds in _REGRESSION else \"f1\"\n",
    "#         res_dict = lib.load_json(os.path.join(method2exp[algo].format(ds), eval_file))\n",
    "\n",
    "#         if algo == \"real\":\n",
    "#             res = f'{res_dict[\"real\"][\"test\"][metric + \"-mean\"]:.4f}' \n",
    "#             if show_std: res += f'+-{res_dict[\"real\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "#         else:\n",
    "#             res = f'{res_dict[\"synthetic\"][\"test\"][metric + \"-mean\"]:.4f}'\n",
    "#             if show_std: res += f'+-{res_dict[\"synthetic\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "\n",
    "#         algo_res.append(res)\n",
    "#     df.loc[len(df)] = [algo] + algo_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1274f69356c75f21c6849ca208d8a507ada71789977a5b65674864f6a32d68ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
