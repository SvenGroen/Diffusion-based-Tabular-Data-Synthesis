{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "This notebook was used to create analytics for the corresponding master thesis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating results to DataFrame\n",
    "This code section loads the final evaluation experiments results and creates a pandas dataframe, displaying all results in a nice overview."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, create a `secrets.json` file in the following format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Experiment_Folder\": \"PATH/TO/YOUR/EXPERIMENT_RESULTS\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>sim_score</th>\n",
       "      <th>basic_score</th>\n",
       "      <th>corr_score</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>sup_score</th>\n",
       "      <th>pmse_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tvae</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smote</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ctabgan</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.7406</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctabgan+</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.7503</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.0186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tab-ddpm</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tab-ddpm-bgm</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tab-ddpm-ft</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.8691</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ctabgan_simTune</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ctabgan+_simTune</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tvae_simTune</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.8146</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tab-ddpm-simTune</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.4196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tab-ddpm-bgm-simTune</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tab-ddpm-ft-simTune</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tab-ddpm-simTune-minmax</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.5575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tab-ddpm-bgm-simTune-minmax</td>\n",
       "      <td>0.8568</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tab-ddpm-bgm-simTune-none</td>\n",
       "      <td>0.8546</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.3693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         method     acc      f1 roc_auc sim_score basic_score  \\\n",
       "0                          real  0.8742  0.8152  0.9276    0.9598      0.9922   \n",
       "1                          tvae  0.8450  0.7805  0.9003    0.6575      0.8544   \n",
       "2                         smote  0.8582  0.7912  0.9104    0.7228      0.9528   \n",
       "3                       ctabgan  0.8499  0.7750  0.8995    0.7406      0.9397   \n",
       "4                      ctabgan+  0.8547  0.7747  0.9070    0.7503      0.9692   \n",
       "5                      tab-ddpm  0.8598  0.7941  0.9128    0.7586      0.9730   \n",
       "6                  tab-ddpm-bgm  0.8632  0.7985  0.9165    0.7418      0.9642   \n",
       "7                   tab-ddpm-ft  0.7849  0.5516  0.8212    0.5951      0.4950   \n",
       "8               ctabgan_simTune  0.8500  0.7756  0.8999    0.7405      0.9385   \n",
       "9              ctabgan+_simTune  0.8507  0.7683  0.9018    0.7839      0.9701   \n",
       "10                 tvae_simTune  0.8447  0.7805  0.9004    0.6577      0.8555   \n",
       "11             tab-ddpm-simTune  0.8556  0.7823  0.9078    0.8520      0.9764   \n",
       "12         tab-ddpm-bgm-simTune  0.8586  0.7917  0.9109    0.8567      0.9823   \n",
       "13          tab-ddpm-ft-simTune  0.7665  0.4506  0.7116    0.5883      0.5125   \n",
       "14      tab-ddpm-simTune-minmax  0.8561  0.7779  0.9100    0.8686      0.9375   \n",
       "15  tab-ddpm-bgm-simTune-minmax  0.8568  0.7871  0.9088    0.8555      0.9812   \n",
       "16    tab-ddpm-bgm-simTune-none  0.8546  0.7837  0.9067    0.8334      0.9747   \n",
       "\n",
       "   corr_score ml_score sup_score pmse_score  \n",
       "0      0.9433   0.9975    0.9839     0.8820  \n",
       "1      0.8139   0.9620    0.6572     0.0000  \n",
       "2      0.8651   0.9925    0.8038     0.0000  \n",
       "3      0.8321   0.9845    0.9468     0.0000  \n",
       "4      0.8818   0.9902    0.8915     0.0186  \n",
       "5      0.9189   0.9923    0.8741     0.0349  \n",
       "6      0.9183   0.9955    0.8307     0.0004  \n",
       "7      0.6482   0.8691    0.9633     0.0000  \n",
       "8      0.8328   0.9841    0.9474     0.0000  \n",
       "9      0.8884   0.9866    0.9075     0.1668  \n",
       "10     0.8146   0.9621    0.6563     0.0000  \n",
       "11     0.9210   0.9910    0.9522     0.4196  \n",
       "12     0.8579   0.9913    0.9197     0.5323  \n",
       "13     0.6190   0.8182    0.9920     0.0000  \n",
       "14     0.9296   0.9901    0.9282     0.5575  \n",
       "15     0.9127   0.9921    0.9151     0.4763  \n",
       "16     0.9157   0.9917    0.9154     0.3693  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tabsynth import lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = os.path.join(json.load(open(\"secrets.json\", \"r\"))[\"Experiment_Folder\"],\"adult\")\n",
    "\n",
    "method2exp = {      \n",
    "    \"real\":                         \"REAL_baseline/outputs/exp/adult/ddpm_real/final_eval/\",\n",
    "    \"tvae\":                         \"TVAE_identity_ml/outputs/exp/adult/tvae/final_eval/\",\n",
    "    \"smote\":                        \"SMOTE_identity/outputs/exp/adult/smote/final_eval/\",\n",
    "    \"ctabgan\":                      \"CTABGAN_identity_ml/outputs/exp/adult/ctabgan/final_eval/\",\n",
    "    \"ctabgan+\":                     \"CTABGAN_Plus_identity_ml/outputs/exp/adult/ctabgan-plus/final_eval/\",\n",
    "    \"tab-ddpm\":                     \"TabDDPM_identity_ml_q/outputs/exp/adult/ddpm_identity_best/final_eval/\",\n",
    "    \"tab-ddpm-bgm\":                 \"TabDDPM_bgm_ml_q/outputs/exp/adult/ddpm_bgm_best/final_eval/\",\n",
    "    \"tab-ddpm-ft\" :                 \"TabDDPM_ft_ml_q/outputs/exp/adult/ddpm_ft_best/final_eval/\",\n",
    "    \"ctabgan_simTune\":              \"CTABGAN_identity_s/outputs/exp/adult/ctabgan/final_eval\",\n",
    "    \"ctabgan+_simTune\":             \"CTABGAN_Plus_identity_s/outputs/exp/adult/ctabgan-plus/final_eval\",#\n",
    "    \"tvae_simTune\":                 \"TVAE_identity_s/outputs/exp/adult/tvae/final_eval\",\n",
    "    \"tab-ddpm-simTune\":             \"TabDDPM_identity_s_q/outputs/exp/adult/ddpm_identity_sim_tune_best/final_eval/\",\n",
    "    \"tab-ddpm-bgm-simTune\" :        \"TabDDPM_bgm_s_q/outputs/exp/adult/ddpm_bgm_sim_tune_best/final_eval/\",\n",
    "    \"tab-ddpm-ft-simTune\":          \"TabDDPM_ft_s_q/outputs/exp/adult/ddpm_ft_sim_tune_quantile_best/final_eval/\",\n",
    "    \"tab-ddpm-simTune-minmax\":      \"TabDDPM_identity_s_m/outputs/exp/adult/ddpm_identity_sim_tune_minmax_best/final_eval/\",\n",
    "    \"tab-ddpm-bgm-simTune-minmax\":  \"TabDDPM_bgm_s_m/outputs/exp/adult/ddpm_bgm_sim_tune_minmax_best/final_eval/\",\n",
    "    \"tab-ddpm-bgm-simTune-none\":     \"TabDDPM_bgm_s_n/outputs/exp/adult/ddpm_bgm_sim_tune_none_best/final_eval/\",#\n",
    "} \n",
    "for k,v in method2exp.items():\n",
    "    method2exp[k] = Path(os.path.join(base_path, v))\n",
    "\n",
    "eval_file = \"eval_catboost.json\"\n",
    "sim_file = \"results_similarity.json\"\n",
    "eval_sim = \"eval_similarity.json\"\n",
    "show_std = False\n",
    "columns = [\"method\"] \n",
    "# df = pd.DataFrame(columns=[\"method\"] + [_[:3].upper() for _ in DATASETS])\n",
    "df = []\n",
    "for algo in method2exp: \n",
    "    base_df = pd.DataFrame([algo], columns=[\"method\"])\n",
    "    metric_df = pd.DataFrame()\n",
    "    metrics=[\"acc\",\"f1\",\"roc_auc\"]\n",
    "\n",
    "    if not os.path.exists(method2exp[algo] / eval_file):\n",
    "        print(f\"File {eval_file} not found for {algo}\")\n",
    "        metric_df = pd.DataFrame([[\"---\"]*len(metrics)], columns=metrics)\n",
    "\n",
    "    else:\n",
    "        res_dict = lib.load_json(method2exp[algo] / eval_file)\n",
    "        for metric in metrics:\n",
    "            if algo == \"real\":\n",
    "                res = f'{res_dict[\"real\"][\"test\"][metric + \"-mean\"]:.4f}' \n",
    "                if show_std: res += f'+-{res_dict[\"real\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "                metric_df[metric] = [res]\n",
    "            else:\n",
    "                res = f'{res_dict[\"synthetic\"][\"test\"][metric + \"-mean\"]:.4f}'\n",
    "                if show_std: res += f'+-{res_dict[\"synthetic\"][\"test\"][metric + \"-std\"]:.4f}'\n",
    "                metric_df[metric] = [res]\n",
    "\n",
    "    sim_metrics = [\"score\", \"basic_score\",\"corr_score\", \"ml_score\",\"sup_score\", \"pmse_score\"]\n",
    "\n",
    "    if os.path.exists(method2exp[algo] / eval_sim):\n",
    "        sim_res_dict = lib.load_json(method2exp[algo] / eval_sim)\n",
    "        tmp = {}\n",
    "        for k,v in sim_res_dict.items():\n",
    "            if \"count\" in k: continue\n",
    "            if \"std\" in k and show_std: \n",
    "                if show_std:\n",
    "                    v = f'+-{float(v):.4f}'\n",
    "                continue\n",
    "            # if \"mean\" in k remove \"-mean\" from key\n",
    "            if \"mean\" in k: \n",
    "                k = k.replace(\"-mean\", \"\")\n",
    "                v = f'{float(v):.4f}'\n",
    "            tmp[k] = v \t    \n",
    "            \n",
    "        sim_df = pd.DataFrame([tmp], columns=sim_metrics)\n",
    "\n",
    "    else:\n",
    "        sim_res_dict = lib.load_json(method2exp[algo] / sim_file)\n",
    "        sim_df = pd.DataFrame([sim_res_dict[\"sim_score\"]], columns=sim_metrics)\n",
    "    # rename score to sim_score\n",
    "    sim_df = sim_df.rename(columns={\"score\": \"sim_score\"})    \n",
    "    # format all floats to :.4f\n",
    "    sim_df = sim_df.applymap(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "\n",
    "    base_df = pd.concat([base_df, metric_df, sim_df], axis=1)\n",
    "    \n",
    "    df.append(base_df)\n",
    "\n",
    "\n",
    "calculate_diff = False\n",
    "results = pd.concat(df, axis=0)\n",
    "metrics = results.columns.tolist()\n",
    "metrics.remove(\"method\")\n",
    "cols= [\"method\"]\n",
    "if calculate_diff:\n",
    "    for metric in metrics:\n",
    "        results[metric] = pd.to_numeric(results[metric])\n",
    "        results[f\"{metric}-diff\"] = results[metric] - results.loc[results[\"method\"] == \"real\", metric].values[0]\n",
    "        cols.append(metric)\n",
    "        cols.append(f\"{metric}-diff\")\n",
    "    results=results.reindex(cols, axis=1)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex\n",
    "export above results to latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round all numeric values in the table\n",
    "# transform all numeric strings to float\n",
    "results = results.applymap(lambda x: float(x) if isinstance(x, str) and x.replace(\".\",\"\",1).isdigit() else x)\n",
    "results=results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SvenG\\AppData\\Local\\Temp\\ipykernel_35120\\22810788.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  output=results_[[\"method\", \"acc\",\"f1\",\"roc_auc\"]].round(3).to_latex(index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrr} \\\\toprule                    method &   acc &    f1 &  roc\\\\_auc \\\\ \\\\midrule tab-ddpm-bgm-simTune-none & 0.855 & 0.784 &    0.907 \\\\ \\\\bottomrule \\\\end{tabular} '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of real, tvae, ctabgan, ctabgan+, smote, ddpm\n",
    "results_ = results[results[\"method\"].isin([\"tab-ddpm-bgm-simTune-none\"])]\n",
    "# results_ = results\n",
    "# subser sim_score, basic_score, corr_score, ml_score, sup_score, pmse_score as latex table\n",
    "# output=results_[[\"method\", \"sim_score\", \"basic_score\", \"corr_score\", \"ml_score\", \"sup_score\", \"pmse_score\"]].round(3).to_latex(index=False)\n",
    "output=results_[[\"method\", \"acc\",\"f1\",\"roc_auc\"]].round(3).to_latex(index=False)\n",
    "# remove any \"\\n\" in the table and replace with \" \" and any \\\\ to \\\n",
    "output = output.replace(\"\\n\", \" \").replace(\"\\\\\\\\\", \"\\\\\").replace(\"\\\\\\\\\", \"\\\\\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SvenG\\AppData\\Local\\Temp\\ipykernel_6108\\1700752336.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  results.round(3).to_latex(index=False, escape=False, column_format=\"lrrrrrr\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrr}\\n\\\\toprule\\n                     method &   acc &    f1 &  roc_auc &  sim_score &  basic_score &  corr_score &  ml_score &  sup_score &  pmse_score \\\\\\\\\\n\\\\midrule\\n                       real & 0.874 & 0.815 &    0.928 &      0.960 &        0.992 &       0.943 &     0.998 &      0.984 &       0.882 \\\\\\\\\\n                   tab-ddpm & 0.860 & 0.794 &    0.913 &      0.759 &        0.973 &       0.919 &     0.992 &      0.874 &       0.035 \\\\\\\\\\n               tab-ddpm-bgm & 0.863 & 0.798 &    0.916 &      0.742 &        0.964 &       0.918 &     0.996 &      0.831 &       0.000 \\\\\\\\\\n           tab-ddpm-simTune & 0.856 & 0.782 &    0.908 &      0.852 &        0.976 &       0.921 &     0.991 &      0.952 &       0.420 \\\\\\\\\\n       tab-ddpm-bgm-simTune & 0.859 & 0.792 &    0.911 &      0.857 &        0.982 &       0.858 &     0.991 &      0.920 &       0.532 \\\\\\\\\\n    tab-ddpm-simTune-minmax & 0.856 & 0.778 &    0.910 &      0.869 &        0.938 &       0.930 &     0.990 &      0.928 &       0.558 \\\\\\\\\\ntab-ddpm-bgm-simTune-minmax & 0.857 & 0.787 &    0.909 &      0.856 &        0.981 &       0.913 &     0.992 &      0.915 &       0.476 \\\\\\\\\\n                tab-ddpm-ft & 0.785 & 0.552 &    0.821 &      0.595 &        0.495 &       0.648 &     0.869 &      0.963 &       0.000 \\\\\\\\\\n        tab-ddpm-ft-simTune & 0.766 & 0.451 &    0.712 &      0.588 &        0.512 &       0.619 &     0.818 &      0.992 &       0.000 \\\\\\\\\\n                      smote & 0.858 & 0.791 &    0.910 &      0.723 &        0.953 &       0.865 &     0.992 &      0.804 &       0.000 \\\\\\\\\\n                   ctabgan+ & 0.855 & 0.775 &    0.907 &      0.750 &        0.969 &       0.882 &     0.990 &      0.892 &       0.019 \\\\\\\\\\n                    ctabgan & 0.850 & 0.775 &    0.900 &      0.741 &        0.940 &       0.832 &     0.984 &      0.947 &       0.000 \\\\\\\\\\n            ctabgan_simTune & 0.850 & 0.776 &    0.900 &      0.740 &        0.938 &       0.833 &     0.984 &      0.947 &       0.000 \\\\\\\\\\n                       tvae & 0.845 & 0.780 &    0.900 &      0.658 &        0.854 &       0.814 &     0.962 &      0.657 &       0.000 \\\\\\\\\\n               tvae_simTune & 0.845 & 0.780 &    0.900 &      0.658 &        0.856 &       0.815 &     0.962 &      0.656 &       0.000 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return all tvae and ctabgan+ results separeted by a \"&\"\" for latex table\n",
    "results.round(3).to_latex(index=False, escape=False, column_format=\"lrrrrrr\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "These scripts are used to create the plots for all synthetic datasets and save them (or certain parts of it) in specific folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# Not used at the end\n",
    "def combine_images(filename, images_dict, numb_rows, numb_cols, rect_x, rect_y, rect_w, rect_h, horiz_space=0, vert_space=0, name_pos=None, font_path=None, font_size=16):\n",
    "    \"\"\"\n",
    "        Combines rectangular parts of multiple images from a dictionary into a single new image with the specified number of rows and columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        The name of the image file to extract from each image in the dictionary.\n",
    "    images_dict : dict\n",
    "        A dictionary containing the names and paths of the images to extract rectangular parts from.\n",
    "    numb_rows : int\n",
    "        The desired number of rows in the new image.\n",
    "    numb_cols : int\n",
    "        The desired number of columns in the new image.\n",
    "    rect_x : int\n",
    "        The x-coordinate of the top-left corner of the rectangular part to extract from each image.\n",
    "    rect_y : int\n",
    "        The y-coordinate of the top-left corner of the rectangular part to extract from each image.\n",
    "    rect_w : int\n",
    "        The width of the rectangular part to extract from each image.\n",
    "    rect_h : int\n",
    "        The height of the rectangular part to extract from each image.\n",
    "    horiz_space : int, optional\n",
    "        The horizontal space to insert between the rectangular parts in the new image (default is 0).\n",
    "    vert_space : int, optional\n",
    "        The vertical space to insert between the rectangular parts in the new image (default is 0).\n",
    "    name_pos : str, optional\n",
    "        The position to write the name of each image on the new image. Can be either \"top\" or \"bottom\" (default is None).\n",
    "    font_path : str, optional\n",
    "        The path to the font file to use for writing the names (default is None).\n",
    "    font_size : int, optional\n",
    "        The size of the font to use for writing the names (default is 16).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    new_img : PIL.Image.Image\n",
    "        A new image with the rectangular parts of all the specified images combined into a single image.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store all the image parts\n",
    "    image_parts = []\n",
    "\n",
    "    # Iterate over all the entries in the dictionary\n",
    "    for name, path in images_dict.items():\n",
    "        # Construct the full path to the image file\n",
    "        full_path = os.path.join(path, filename)\n",
    "\n",
    "        # Load the image and extract the rectangular part\n",
    "        with Image.open(full_path) as img:\n",
    "            rect = img.crop((rect_x, rect_y, rect_x+rect_w, rect_y+rect_h))\n",
    "            # Append the extracted part to the list of image parts along with its name\n",
    "            image_parts.append((rect, name))\n",
    "\n",
    "    # Calculate the total number of image parts and the required number of rows and columns\n",
    "    total_parts = len(image_parts)\n",
    "    rows = min(numb_rows, total_parts)\n",
    "    cols = min(numb_cols, total_parts)\n",
    "\n",
    "    # Calculate the dimensions of the new image including space between the image parts\n",
    "    part_w, part_h = image_parts[0][0].size\n",
    "    new_w = cols * part_w + (cols-1) * horiz_space\n",
    "    new_h = rows * part_h + (rows-1) * vert_space\n",
    "\n",
    "    # Create a new empty image with the calculated dimensions\n",
    "    new_img = Image.new('RGB', (new_w, new_h), color=\"white\")\n",
    "\n",
    "    # Create a font object for writing the names on the image if specified\n",
    "    if name_pos is not None and font_path is not None:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Iterate over all the image parts and paste them onto the new image\n",
    "    for i, (part, name) in enumerate(image_parts):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        x = col * (part_w + horiz_space)\n",
    "        y = row * (part_h + vert_space)\n",
    "        new_img.paste(part, (x, y))\n",
    "\n",
    "        # Write the name on the image if specified and at the correct position\n",
    "        if name_pos is not None:\n",
    "            draw = ImageDraw.Draw(new_img)\n",
    "            name_w, name_h = draw.textsize(name, font=font)\n",
    "            if name_pos == \"top\":\n",
    "                text_x = x + (part_w - name_w) // 2\n",
    "                text_y = y - name_h - font_size // 2\n",
    "            elif name_pos == \"bottom\":\n",
    "                text_x = x + (part_w - name_w) // 2\n",
    "                text_y = y + part_h + font_size // 2\n",
    "            draw.text((text_x, text_y), name, font=font, fill='white')\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def save_extracted_images(filename, img_dict, rect_x, rect_y, rect_w, rect_h, output_dir, max_h=False, max_w=False, space=20):\n",
    "    \"\"\"\n",
    "    Extracts a rectangular portion of an image based on provided coordinates and saves the processed image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Name of the file to be processed.\n",
    "    img_dict : dict\n",
    "        Dictionary where keys are names and values are paths to the image files.\n",
    "    rect_x : int\n",
    "        The x-coordinate of the top-left corner of the rectangular portion to be extracted.\n",
    "    rect_y : int\n",
    "        The y-coordinate of the top-left corner of the rectangular portion to be extracted.\n",
    "    rect_w : int\n",
    "        The width of the rectangular portion to be extracted.\n",
    "    rect_h : int\n",
    "        The height of the rectangular portion to be extracted.\n",
    "    output_dir : str\n",
    "        Path to the directory where the processed images will be saved.\n",
    "    max_h : bool, optional\n",
    "        If True, replaces rect_h with the maximum height of the image, by default False.\n",
    "    max_w : bool, optional\n",
    "        If True, replaces rect_w with the maximum width of the image, by default False.\n",
    "    space : int, optional\n",
    "        The amount of space (in pixels) to be added to the top, bottom, left, and right of the extracted image, by default 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create output directory with timestamped name\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    timestamp = f\"{filename[:-4]}_{timestamp}\"\n",
    "    output_dir = os.path.join(output_dir, timestamp)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate through each entry in the dict\n",
    "    for name, path in img_dict.items():\n",
    "        # Load the image\n",
    "        img = Image.open(os.path.join(path, filename))\n",
    "\n",
    "        # Get the maximum width and height of the image\n",
    "        max_width, max_height = img.size\n",
    "\n",
    "        # If max_h is True, replace rect_h with max_height\n",
    "        if max_h:\n",
    "            rect_h = max_height\n",
    "\n",
    "        # If max_w is True, replace rect_w with max_width\n",
    "        if max_w:\n",
    "            rect_w = max_width\n",
    "\n",
    "        # Crop the image based on the provided rectangle coordinates\n",
    "        cropped_img = img.crop((rect_x, rect_y, rect_x+rect_w, rect_y+rect_h))\n",
    "\n",
    "        # Add vertical and horizontal white space to the cropped image\n",
    "        new_width = cropped_img.width + space*2\n",
    "        new_height = cropped_img.height + space*2\n",
    "        new_img = Image.new(mode='RGB', size=(new_width, new_height), color=(255, 255, 255))\n",
    "        new_img.paste(cropped_img, (space, space))\n",
    "\n",
    "        # Save the processed image in the output directory\n",
    "        output_path = os.path.join(output_dir, f\"{name}.jpg\")\n",
    "        new_img.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = json.load(open(\"secrets.json\", \"r\"))[\"Experiment_Folder\"]\n",
    "\n",
    "img_dict = {\n",
    "    \"real\": \"changed_plots/real/plots\",\n",
    "    \"tab-ddpm\": \"changed_plots/tab-ddpm/plots\",\n",
    "    \"tab-ddpm-bgm\": \"changed_plots/tab-ddpm-bgm/plots\",\n",
    "    \"tab-ddpm-simTune\": \"changed_plots/tab-ddpm-simTune/plots\",\n",
    "    \"tab-ddpm-bgm-simTune\" : \"changed_plots/tab-ddpm-bgm-simTune/plots\",\n",
    "    \"tab-ddpm-simTune-minmax\": \"changed_plots/tab-ddpm-simTune-minmax/plots\",\n",
    "    \"tab-ddpm-bgm-simTune-minmax\": \"changed_plots/tab-ddpm-bgm-simTune-minmax/plots\",\n",
    "    \"tab-ddpm-bgm-simTune-none\": \"changed_plots/tab-ddpm-bgm-simTune-none/plots\",#\n",
    "    \"tab-ddpm-ft\" : \"changed_plots/tab-ddpm-ft/plots\",\n",
    "    \"tab-ddpm-ft-simTune\": \"changed_plots/tab-ddpm-ft-simTune/plots\",\n",
    "    \"smote\": \"changed_plots/smote/plots\",\n",
    "    \"ctabgan+\": \"changed_plots/ctabgan+/plots\",\n",
    "    \"ctabgan+_simTune\": \"changed_plots/ctabgan+_simTune/plots\",#\n",
    "    \"ctabgan\": \"changed_plots/ctabgan/plots\",\n",
    "    \"ctabgan_simTune\": \"changed_plots/ctabgan_simTune/plots\",\n",
    "    \"tvae\": \"changed_plots/tvae/plots\",\n",
    "    \"tvae_simTune\": \"changed_plots/tvae_simTune/plots\",\n",
    "} \n",
    "for k,v in img_dict.items():\n",
    "    img_dict[k] = Path(os.path.join(base_path, v))\n",
    "    img_dict[k].mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract certain image parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir= os.path.join(base_path, \"out_images\")\n",
    "\n",
    "#  correlation difference\n",
    "# extract_dict={\"filename\":\"correlation_difference.png\",\n",
    "#               \"rect_x\":1600, \n",
    "#               \"rect_y\":0, \n",
    "#               \"rect_w\":800, \n",
    "#               \"rect_h\":1000,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":True,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "# # distribution-education\n",
    "extract_dict={\"filename\":\"distributions.png\",\n",
    "              \"rect_x\":540, \n",
    "              \"rect_y\":80, \n",
    "              \"rect_w\":530, \n",
    "              \"rect_h\":540,\n",
    "                \"space\":0,\n",
    "               \"max_h\":False,\n",
    "               \"max_w\":False}\n",
    "\n",
    "# # distribution-age\n",
    "# extract_dict={\"filename\":\"distributions.png\",\n",
    "#               \"rect_x\":1065, \n",
    "#               \"rect_y\":1280, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":450,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":False,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "# # distribution-hours-per-week\n",
    "# extract_dict={\"filename\":\"distributions.png\",\n",
    "#               \"rect_x\":540, \n",
    "#               \"rect_y\":2480, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":450,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":False,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "# PCA - fake\n",
    "# extract_dict={\"filename\":\"pca.png\",\n",
    "#               \"rect_x\":580, \n",
    "#               \"rect_y\":40, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":550,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":False,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "# # # distribution-full\n",
    "# extract_dict={\"filename\":\"distributions.png\",\n",
    "#               \"rect_x\":0, \n",
    "#               \"rect_y\":0, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":450,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":True,\n",
    "#                \"max_w\":True}\n",
    "\n",
    "\n",
    "# # # # cumsum-full\n",
    "# extract_dict={\"filename\":\"cumsums.png\",\n",
    "#               \"rect_x\":0, \n",
    "#               \"rect_y\":0, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":450,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":True,\n",
    "#                \"max_w\":True}\n",
    "\n",
    "# #cumsum-native-country\n",
    "# extract_dict={\"filename\":\"cumsums.png\",\n",
    "#               \"rect_x\":540, \n",
    "#               \"rect_y\":1290, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":560,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":False,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "# #cumsum-hoursperweek\n",
    "# extract_dict={\"filename\":\"cumsums.png\",\n",
    "#               \"rect_x\":540, \n",
    "#               \"rect_y\":2470, \n",
    "#               \"rect_w\":530, \n",
    "#               \"rect_h\":460,\n",
    "#                 \"space\":0,\n",
    "#                \"max_h\":False,\n",
    "#                \"max_w\":False}\n",
    "\n",
    "save_extracted_images(img_dict=img_dict, **extract_dict, output_dir=out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Structure of the Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the current working directory (c:\\Users\\SvenG\\Documents\\Git_Repos\\Tabular-Data-Synthesis-Repos\\tab-ddpm):\n",
      "+---üìÅoutputs\n",
      "|   +---üìÅsrc\n",
      "|   |   +---üìÅtabsynth\n",
      "|   |   |   +---üìÅexp\n",
      "+---üìÅprocessor_state\n",
      "+---üìÅsrc\n",
      "|   +---üìÅtabsynth\n",
      "|   |   +---üìÅCTABGAN\n",
      "|   |   |   +---üìÅmodel\n",
      "|   |   |   |   +---üìÅeval\n",
      "|   |   |   |   +---üìÅpipeline\n",
      "|   |   |   |   +---üìÅsynthesizer\n",
      "|   |   +---üìÅCTABGAN_Plus\n",
      "|   |   |   +---üìÅmodel\n",
      "|   |   |   |   +---üìÅeval\n",
      "|   |   |   |   +---üìÅpipeline\n",
      "|   |   |   |   +---üìÅprivacy_utils\n",
      "|   |   |   |   +---üìÅsynthesizer\n",
      "|   |   |   +---üìÅmodel copy\n",
      "|   |   |   |   +---üìÅeval\n",
      "|   |   |   |   +---üìÅpipeline\n",
      "|   |   |   |   +---üìÅprivacy_utils\n",
      "|   |   |   |   +---üìÅsynthesizer\n",
      "|   |   +---üìÅCTGAN\n",
      "|   |   +---üìÅdata\n",
      "|   |   +---üìÅevaluation\n",
      "|   |   +---üìÅexp\n",
      "|   |   +---üìÅlib\n",
      "|   |   +---üìÅprocessor_state\n",
      "|   |   +---üìÅscripts\n",
      "|   |   +---üìÅsmote\n",
      "|   |   +---üìÅtabular_processing\n",
      "|   |   |   +---üìÅbgm_utils\n",
      "|   |   |   +---üìÅft_utils\n",
      "|   |   +---üìÅtab_ddpm\n",
      "|   |   +---üìÅtuned_models\n",
      "|   |   |   +---üìÅcatboost\n",
      "|   |   |   +---üìÅmlp\n",
      "|   +---üìÅtabsynth.egg-info\n",
      "+---üìÅtests\n",
      "|   +---üìÅdata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def print_directory_contents(path, ignore_list=None, allowed_extensions=None, keep_closed=None, level=0):\n",
    "    if ignore_list is None:\n",
    "        ignore_list = []\n",
    "\n",
    "    if allowed_extensions is None:\n",
    "        allowed_extensions = ['.py', '.md']\n",
    "\n",
    "    if keep_closed is None:\n",
    "        keep_closed = []\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        # Add indentation for sub-directories/files\n",
    "        indent = '|   ' * level\n",
    "\n",
    "        for item in os.listdir(path):\n",
    "            item_path = os.path.join(path, item)\n",
    "\n",
    "            # Check if the item should be ignored\n",
    "            if item in ignore_list:\n",
    "                continue\n",
    "\n",
    "            if os.path.isdir(item_path):\n",
    "                # Print directory name\n",
    "                print(f\"{indent}+---üìÅ{item}\")\n",
    "\n",
    "                # Check if the directory is in the keep_closed list\n",
    "                if item not in keep_closed:\n",
    "                    # Recursively call the function for sub-directories\n",
    "                    print_directory_contents(item_path, ignore_list, allowed_extensions, keep_closed, level + 1)\n",
    "            else:\n",
    "                continue\n",
    "                # Only print files with allowed extensions\n",
    "                if any(item.endswith(ext) for ext in allowed_extensions):\n",
    "                    # Print file name\n",
    "                    print(f\"{indent}+--- {item}\")\n",
    "    else:\n",
    "        print(\"The given path does not exist.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the current working directory as the starting path\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Specify the folders/files to ignore\n",
    "    ignore_list = ['.git', \n",
    "                   '.vscode', \n",
    "                   '__pycache__', \n",
    "                   \".amlignore\",\n",
    "                   \".gitignore\",\n",
    "                   \".github\",\n",
    "                   \".gitmodules\",\n",
    "                   \".pytest_cache\",\n",
    "                   \"tmp\",\n",
    "                   \"__init__.py\",\n",
    "                   \"catboost_info\",\n",
    "                   \"legacy\"]\n",
    "\n",
    "    # Specify the allowed file types\n",
    "    allowed_extensions = ['.py', '.md']\n",
    "\n",
    "    # Specify the keep_closed list\n",
    "    keep_closed = ['exp', \n",
    "                   \"data\",\n",
    "                   \"CTAB-GAN\",\n",
    "                   \"CTAB-GAN-Plus\",\n",
    "                   \"CTGAN\",\n",
    "                   \"legacy\",\n",
    "                   \"smote\",\n",
    "                   \"CTGAN\",\n",
    "                   ]\n",
    "\n",
    "    print(f\"Contents of the current working directory ({cwd}):\")\n",
    "    print_directory_contents(cwd, ignore_list, allowed_extensions, keep_closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1274f69356c75f21c6849ca208d8a507ada71789977a5b65674864f6a32d68ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
